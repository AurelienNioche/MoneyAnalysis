import multiprocessing
import os
import numpy as np
from tqdm import tqdm
import pickle

import simulation.economy

import backup.structure

import format.old.format
import stats.mean_comparison


def _run(param):

    e = simulation.economy.Economy(**param)
    return param, e.run()


def _log(string, f_name):
    with open(f_name, 'a') as f:
        f.write(string)


def _get_parameters(data):

    # ----- global params ------ #
    n_good = 3
    t_max = 100
    economy_model = 'prod: i-1'
    agent_model = 'RLAgent'

    base_cog = [cog for cog in data.cognitive_parameters if len(cog) == 3]

    params = []

    for i in range(len(data.room_id)):

        heterogeneous = len(data.cognitive_parameters[i]) != 3
        seed = np.random.randint(2**32-1)

        if heterogeneous:

            cognitive_parameters = _get_new_heterogeneous_parameters(
                base_cog=base_cog,
                distribution=data.distribution[i]
            )

        else:

            cognitive_parameters = data.cognitive_parameters[i]

        p = {
            'cognitive_parameters': cognitive_parameters,
            'seed': seed,
            't_max': t_max,
            'economy_model': economy_model,
            'agent_model': agent_model,
            'n_good': n_good,
            'distribution': data.distribution[i],
            'heterogeneous': heterogeneous,
            'room_id': data.room_id[i],
        }

        params.append(p)

    return params


def _get_new_heterogeneous_parameters(base_cog, distribution):

    heterogeneous_cog = \
        np.asarray(base_cog)[
            np.random.choice(
                range(len(base_cog)),
                size=np.sum(np.asarray(distribution))
            )
        ]

    return heterogeneous_cog


def _get_sig_results(data):

    monetary_bhv = data.monetary_bhv

    # reformat each economies to compress on agents
    monetary_over_user = [
        format.old.format.monetary_bhv_over_user(m)
        for m in monetary_bhv
    ]

    # Now we can do stats
    sig = [stats.mean_comparison.run(i) for i in monetary_over_user]

    # print(sig)
    results = np.asarray([
        i[0][-1] < 0.05 and i[1][-1] < 0.05
        for i in sig
    ])[np.asarray(data.room_id)]

    return results


def _produce_data(params):

    max_ = len(params)

    data = backup.structure.Data()

    with multiprocessing.Pool(processes=os.cpu_count()) as p:

        with tqdm(total=max_) as pbar:
            for pr, b in p.imap_unordered(_run, params):
                data.append(bkp=b, param=pr)
                pbar.update()

    return data


def run(selected_batch=None):

    # ----- files -------- #

    f_name = 'data/supplementary.p'

    if selected_batch is None:
        log_f_name = 'data/supplementary_exploitation_log.txt'

    else:
        log_f_name = \
            f'data/supplementary_exploitation_log_batch_{selected_batch}.txt'

    params_f_name = 'data/params_supplementary_exploitation.p'

    # ----- load data  ------ #

    with open(f_name, 'rb') as f:

        if selected_batch is None:
            bkp = pickle.load(f)
        else:
            bkp = (pickle.load(f)[selected_batch], )

    # ----- flush logs --------- #
    with open(log_f_name, 'w') as f:
        f.write('')

    # ------ global params ------- #

    n_batch = len(bkp)

    # n trial for each batch
    # (assessing its robustness by varying heterogeneous cognitive parameters)
    max_trial = 100

    # each of the list corresponds to a batch
    # one list contains list of dic params (one for each trial)
    new_params = [[] for _ in range(n_batch)]

    print(f'Treating {n_batch} batchs.')

    with tqdm(total=max_trial*n_batch) as pbar:

        for idx, b in enumerate(bkp):

            # Counter (increased by one when
            # all economies with homogeneous
            # cog param return true significant
            # statement while the economy
            # with heterogeneous cog param
            # returns false significant statement.)
            homogeneous_true_heterogeneous_false = 0

            for trial in range(max_trial):

                params = _get_parameters(data=b)

                new_params[idx].append(params)

                # Run simulations
                data = _produce_data(params=params)

                # Do stats
                results = _get_sig_results(data=data)

                # if all simulations using homogeneous cognitive
                # parameters are significant (money emergence) and
                # the simulations using heterogeneous cognitive parameters
                # are not (no money emerges) increment the counter
                homogeneous_true_heterogeneous_false += \
                    np.all(results[:-1]) and not results[-1]

                pbar.update()

            stars = '*' * 5
            string = \
                f'{stars} batch {idx} {stars} \n' \
                f' {homogeneous_true_heterogeneous_false}/{max_trial} \n'

            _log(string, f_name=log_f_name)
            print(string)

    # Save tested params
    with open(params_f_name, 'wb') as f:
        pickle.dump(new_params, f)


def main():
    # run_all()
    run(selected_batch=6)


if __name__ == "__main__":

    main()