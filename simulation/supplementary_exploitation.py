import multiprocessing
import os
import numpy as np
from tqdm import tqdm
import pickle

import simulation.economy

import backup.structure

import analysis.tools.format
import analysis.stats.mean_comparison


def _run(param):

    e = simulation.economy.Economy(**param)
    return param, e.run()


def _log(string, f_name):
    with open(f_name, 'a') as f:
        f.write(string)


def _get_new_heterogeneous_parameters(base_cog, distribution):

    heterogeneous_cog = \
        np.asarray(base_cog)[
            np.random.choice(
                range(len(base_cog)),
                size=np.sum(np.asarray(distribution))
            )
        ]

    return heterogeneous_cog


def _get_sig_results(data):

    monetary_bhv = data.monetary_bhv

    # reformat each economies to compress on agents
    monetary_over_user = [
        analysis.tools.format.monetary_bhv_over_user(m)
        for m in monetary_bhv
    ]

    # Now we can do stats
    sig = [analysis.stats.mean_comparison.run(i) for i in monetary_over_user]

    # print(sig)
    results = np.asarray([
        i[0][-1] < 0.05 and i[1][-1] < 0.05
        for i in sig
    ])[np.asarray(data.room_id)]

    return results


def _produce_data(params):

    max_ = len(params)

    data = backup.structure.Data()

    with multiprocessing.Pool(processes=os.cpu_count()) as p:

        with tqdm(total=max_) as pbar:
            for pr, b in p.imap_unordered(_run, params):
                data.append(bkp=b, param=pr)
                pbar.update()

    return data


def run_all():

    # ----- files -------- #

    f_name = 'data/supplementary.p'
    log_f_name = 'data/supplementary_exploitation_log.txt'
    params_f_name = 'data/params_supplementary_exploitation.p'

    # ----- load data  ------ #

    with open(f_name, 'rb') as f:
        bkp = pickle.load(f)

    # ----- flush logs --------- #
    with open(log_f_name, 'w') as f:
        f.write('')

    # ----- global params ------ #
    n_good = 3
    t_max = 100
    economy_model = 'prod: i-1'
    agent_model = 'RLAgent'
    max_trial = 100
    # each of the list corresponds to a batch
    # one list contains list of dic params (one for each trial)
    new_params = [[] for _ in range(len(bkp))]

    print(f'Treating {len(bkp)} batchs.')

    with tqdm(total=max_trial*len(bkp)) as pbar:

        for idx, b in enumerate(bkp):

            homogeneous_true_heterogeneous_false = 0
            base_cog = [cog for cog in b.cognitive_parameters if len(cog) == 3]

            for trial in range(max_trial):

                params = []

                for i in range(len(b.room_id)):

                    heterogeneous = len(b.cognitive_parameters[i]) != 3
                    seed = np.random.randint(2**32-1)

                    if heterogeneous:

                        cognitive_parameters = _get_new_heterogeneous_parameters(
                            base_cog=base_cog,
                            distribution=b.distribution[i]
                        )

                    else:

                        cognitive_parameters = b.cognitive_parameters[i]

                    p = {
                        'cognitive_parameters': cognitive_parameters,
                        'seed': seed,
                        't_max': t_max,
                        'economy_model': economy_model,
                        'agent_model': agent_model,
                        'n_good': n_good,
                        'distribution': b.distribution[i],
                        'heterogeneous': heterogeneous,
                        'room_id': b.room_id[i],
                    }

                    params.append(p)

                new_params[idx].append(params)

                data = _produce_data(params)

                results = _get_sig_results(data)

                homogeneous_true_heterogeneous_false += \
                    np.all(results[:-1]) and not results[-1]

                pbar.update()

            stars = '*' * 5
            string = \
                f'{stars} batch {idx} {stars} \n {homogeneous_true_heterogeneous_false}/{max_trial} \n'

            _log(string, f_name=log_f_name)
            print(string)

    # Save tested params
    with open(params_f_name, 'wb') as f:
        pickle.dump(new_params, f)


def run_one(selected_batch):
    # ----- files -------- #

    f_name = 'data/supplementary.p'
    log_f_name = f'data/supplementary_exploitation_log_batch_{selected_batch}.txt'
    # params_f_name = 'data/params_supplementary_exploitation.p'

    # ----- load data  ------ #

    with open(f_name, 'rb') as f:
        b = pickle.load(f)[selected_batch]

    # ----- flush logs --------- #
    with open(log_f_name, 'w') as f:
        f.write('')

    # ----- eco params ------ #
    n_good = 3
    t_max = 100
    economy_model = 'prod: i-1'
    agent_model = 'RLAgent'

    # ---- global params ---- #
    max_trial = 100
    repeat = 10
    mean = []

    print(f'Treating batch {selected_batch}.')

    with tqdm(total=max_trial*repeat) as pbar:

        for _ in range(repeat):

            homogeneous_true_heterogeneous_false = 0
            base_cog = [cog for cog in b.cognitive_parameters if len(cog) == 3]

            for trial in range(max_trial):

                params = []

                for i in range(len(b.room_id)):

                    seed = np.random.randint(2**32-1)
                    heterogeneous = len(b.cognitive_parameters[i]) != 3

                    if heterogeneous:

                        cognitive_parameters = _get_new_heterogeneous_parameters(
                            base_cog=base_cog,
                            distribution=b.distribution[i]
                        )

                    else:

                        cognitive_parameters = b.cognitive_parameters[i]

                    p = {
                        'cognitive_parameters': cognitive_parameters,
                        'seed': seed,
                        't_max': t_max,
                        'economy_model': economy_model,
                        'agent_model': agent_model,
                        'n_good': n_good,
                        'distribution': b.distribution[i],
                        'heterogeneous': heterogeneous,
                        'room_id': b.room_id[i],
                    }

                    params.append(p)

                data = _produce_data(params)

                results = _get_sig_results(data)

                homogeneous_true_heterogeneous_false += \
                    np.all(results[:-1]) and not results[-1]

                pbar.update()

            stars = '*' * 5
            print(stars, f'{homogeneous_true_heterogeneous_false}/{max_trial}', stars)

            mean.append(homogeneous_true_heterogeneous_false)

        print(f'{np.mean(mean)}/10')


def main():
    # run_all()
    run_one(selected_batch=6)


if __name__ == "__main__":

    main()